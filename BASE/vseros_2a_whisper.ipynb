{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def get_direct_file_link(mailru_file_url: str) -> str:\n",
        "    \"\"\"\n",
        "    Преобразует публичную ссылку вида:\n",
        "        https://cloud.mail.ru/public/<key>/<subkey>/<filename>\n",
        "    в прямую ссылку на CDN, по которой можно скачать файл через wget или requests.\n",
        "\n",
        "    Возвращает прямую ссылку для скачивания.\n",
        "    \"\"\"\n",
        "    resp = requests.get(mailru_file_url)\n",
        "    if resp.status_code != 200:\n",
        "        raise RuntimeError(f\"Ошибка {resp.status_code} при запросе {mailru_file_url}\")\n",
        "\n",
        "    match = re.search(r'dispatcher.*?weblink_get.*?url\":\"(.*?)\"', resp.text)\n",
        "    if not match:\n",
        "        raise RuntimeError(\"Не удалось найти CDN ссылку в HTML Mail.ru\")\n",
        "\n",
        "    base_url = match.group(1)\n",
        "    parts = mailru_file_url.strip(\"/\").split(\"/\")[-3:]\n",
        "    return f\"{base_url}/{parts[0]}/{parts[1]}/{parts[2]}\"\n",
        "\n",
        "\n",
        "def download_from_mailru(file_url: str, local_name: str, force: bool = False, show_progress: bool = True):\n",
        "    \"\"\"\n",
        "    Скачивает файл с Mail.ru по публичной ссылке.\n",
        "\n",
        "    Args:\n",
        "        file_url: ссылка на файл в облаке Mail.ru.\n",
        "        local_name: имя файла для сохранения.\n",
        "        force: если True — перекачивает даже если файл уже есть.\n",
        "        show_progress: показывать ли прогресс-бар.\n",
        "    \"\"\"\n",
        "    local_path = Path(local_name)\n",
        "    if local_path.exists() and not force:\n",
        "        print(f\"Файл {local_name} уже существует, пропускаем скачивание.\")\n",
        "        return\n",
        "\n",
        "    direct = get_direct_file_link(file_url)\n",
        "    print(f\"Скачиваем {file_url} → {local_name}\")\n",
        "\n",
        "    with requests.get(direct, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        total_size = int(r.headers.get(\"content-length\", 0))\n",
        "        block_size = 8192\n",
        "        with open(local_name, \"wb\") as f, tqdm(\n",
        "            total=total_size,\n",
        "            unit=\"B\",\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "            desc=f\"Downloading {local_name}\",\n",
        "            disable=not show_progress,\n",
        "        ) as bar:\n",
        "            for chunk in r.iter_content(block_size):\n",
        "                f.write(chunk)\n",
        "                bar.update(len(chunk))\n",
        "\n",
        "    print(f\"Файл {local_name} успешно скачан ({os.path.getsize(local_name)/1e6:.1f} MB).\")"
      ],
      "metadata": {
        "id": "wZWk8M1qXDEL"
      },
      "id": "wZWk8M1qXDEL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ссылки на данные по задаче\n",
        "train_link = \"https://cloud.mail.ru/public/Gsyr/8VxmbhAaZ/train_data.tar\"\n",
        "test_link  = \"https://cloud.mail.ru/public/Gsyr/8VxmbhAaZ/test_data.tar\""
      ],
      "metadata": {
        "id": "QgVL5aZ4XEcQ"
      },
      "id": "QgVL5aZ4XEcQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Если скорость загрузки низкая — это может быть связано с CDN.\n",
        "# Попробуйте перезапустить ячейку: при новом соединении может попасться другой узел CDN,\n",
        "# и загрузка обычно проходит быстрее (2-3 минуты при нормальном узле).\n",
        "download_from_mailru(train_link, \"train_data.tar\")\n",
        "download_from_mailru(test_link, \"test_data.tar\")"
      ],
      "metadata": {
        "id": "zow4IQZfXHVM"
      },
      "id": "zow4IQZfXHVM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Распаковка\n",
        "subprocess.run([\"tar\", \"xf\", \"train_data.tar\"], check=True)\n",
        "subprocess.run([\"tar\", \"xf\", \"test_data.tar\"], check=True)\n",
        "print(\"Готово.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oOyLokOXLF5",
        "outputId": "8d4db213-ae9c-4b98-bb51-96828f30208e"
      },
      "id": "-oOyLokOXLF5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Готово.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/test_opus/audio'\n",
        "files_before = len([f for f in Path(folder_path).rglob('*') if f.is_file()])\n",
        "print(f\"Файлов до удаления: {files_before}\")\n",
        "\n",
        "!find {folder_path} -type f -name \"._*\" -delete\n",
        "\n",
        "files_after = len([f for f in Path(folder_path).rglob('*') if f.is_file()])\n",
        "deleted = files_before - files_after\n",
        "\n",
        "print(f\"Удалено файлов: {deleted}\")\n",
        "print(f\"Файлов после удаления: {files_after}\")"
      ],
      "metadata": {
        "id": "pMOFuQwmXicR"
      },
      "id": "pMOFuQwmXicR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/train_opus/audio'\n",
        "files_before = len([f for f in Path(folder_path).rglob('*') if f.is_file()])\n",
        "print(f\"Файлов до удаления: {files_before}\")\n",
        "\n",
        "!find {folder_path} -type f -name \"._*\" -delete\n",
        "\n",
        "files_after = len([f for f in Path(folder_path).rglob('*') if f.is_file()])\n",
        "deleted = files_before - files_after\n",
        "\n",
        "print(f\"Удалено файлов: {deleted}\")\n",
        "print(f\"Файлов после удаления: {files_after}\")"
      ],
      "metadata": {
        "id": "45aE6o0YXk2Q"
      },
      "id": "45aE6o0YXk2Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import & pipeline starting"
      ],
      "metadata": {
        "id": "MZkX66R_g9Il"
      },
      "id": "MZkX66R_g9Il"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import hmean\n",
        "\n",
        "import torchaudio\n",
        "from transformers import AutoProcessor\n",
        "from transformers import AutoModelForSpeechSeq2Seq\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip -q install torch-audiomentations\n",
        "from torch_audiomentations import Compose, Gain, PolarityInversion, AddColoredNoise, Shift, HighPassFilter, LowPassFilter\n",
        "import librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raSIyQChg-JT",
        "outputId": "82759e1c-0efb-4e6b-e37a-8ac19d6d8b57"
      },
      "id": "raSIyQChg-JT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "SEED=2008\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "Z06kySjuhD-Y"
      },
      "id": "Z06kySjuhD-Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "6wMDxw_4pc17"
      },
      "id": "6wMDxw_4pc17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparing"
      ],
      "metadata": {
        "id": "jLSJ3ofrhXgG"
      },
      "id": "jLSJ3ofrhXgG"
    },
    {
      "cell_type": "code",
      "source": [
        "train_audio_path = '/content/train_opus/audio'\n",
        "test_audio_path = '/content/test_opus/audio'\n",
        "word_bounds_path = '/content/train_opus/word_bounds.json'"
      ],
      "metadata": {
        "id": "zbfLdR1RhZQl"
      },
      "id": "zbfLdR1RhZQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_bounds = json.load(open(word_bounds_path))\n",
        "\n",
        "train_data = pd.DataFrame({'id': [f[:f.find('.')] for f in os.listdir(train_audio_path)]})\n",
        "train_data['label'] = train_data['id'].apply(lambda x: 1 if x in word_bounds else 0)\n",
        "train_data['path'] = train_data['id'].apply(lambda x: f'{train_audio_path}/{x}.opus')\n",
        "\n",
        "pos_items = train_data[train_data['label'] == 1][['id', 'path']].values.tolist()\n",
        "neg_items = train_data[train_data['label'] == 0][['id', 'path']].values.tolist()\n",
        "\n",
        "pos_train, pos_val = train_test_split(pos_items, test_size=0.12, random_state=SEED)\n",
        "neg_train, neg_val = train_test_split(neg_items, test_size=0.12, random_state=SEED)\n",
        "\n",
        "train_items = pos_train + neg_train\n",
        "val_items = pos_val + neg_val\n",
        "\n",
        "random.shuffle(train_items)\n",
        "random.shuffle(val_items)\n",
        "\n",
        "print(f'Train: {len(train_items)} (pos: {len(pos_train)}, neg: {len(neg_train)})')\n",
        "print(f'Val: {len(val_items)} (pos: {len(pos_val)}, neg: {len(neg_val)})')"
      ],
      "metadata": {
        "id": "lzWYpUeahCO8"
      },
      "id": "lzWYpUeahCO8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentations"
      ],
      "metadata": {
        "id": "1QsHJkVmjd0B"
      },
      "id": "1QsHJkVmjd0B"
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioAugmentation:\n",
        "    def __init__(self, sample_rate=16000, use_heavy_aug=True):\n",
        "        self.sample_rate = sample_rate\n",
        "        self.use_heavy_aug = use_heavy_aug\n",
        "\n",
        "        self.augment = Compose(\n",
        "            transforms=[\n",
        "                Gain(min_gain_in_db=-12.0, max_gain_in_db=8.0, p=0.6),\n",
        "                PolarityInversion(p=0.5),\n",
        "                AddColoredNoise(min_snr_in_db=10.0, max_snr_in_db=35.0, min_f_decay=-2.0, max_f_decay=2.0, p=0.6),\n",
        "                Shift(min_shift=-0.15, max_shift=0.15, shift_unit=\"fraction\", rollover=True, p=0.5),\n",
        "                HighPassFilter(min_cutoff_freq=20.0, max_cutoff_freq=400.0, p=0.35),\n",
        "                LowPassFilter(min_cutoff_freq=2000.0, max_cutoff_freq=7500.0, p=0.35),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def apply_time_stretch(self, wav, rate=0.15):\n",
        "        if random.random() > 0.4:\n",
        "            try:\n",
        "                stretch_factor = random.uniform(1.0 - rate, 1.0 + rate)\n",
        "                wav_np = wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "                stretched = librosa.effects.time_stretch(wav_np, rate=stretch_factor)\n",
        "                if len(stretched) > len(wav_np):\n",
        "                    stretched = stretched[:len(wav_np)]\n",
        "                else:\n",
        "                    stretched = np.pad(stretched, (0, max(0, len(wav_np) - len(stretched))))\n",
        "                return stretched\n",
        "            except:\n",
        "                return wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "        return wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "\n",
        "    def apply_pitch_shift(self, wav, n_steps_range=(-2, 2)):\n",
        "        if random.random() > 0.5:\n",
        "            try:\n",
        "                n_steps = random.uniform(n_steps_range[0], n_steps_range[1])\n",
        "                if abs(n_steps) < 0.1:\n",
        "                    return wav\n",
        "                wav_np = wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "                shifted = librosa.effects.pitch_shift(wav_np, sr=self.sample_rate, n_steps=n_steps)\n",
        "                return shifted\n",
        "            except:\n",
        "                return wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "        return wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "\n",
        "    def apply_background_noise(self, wav, noise_level_range=(0.005, 0.03)):\n",
        "        if random.random() > 0.6:\n",
        "            wav_np = wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "            std = np.std(wav_np)\n",
        "            if std < 1e-6:\n",
        "                return wav_np\n",
        "            noise_level = random.uniform(*noise_level_range)\n",
        "            noise = np.random.randn(len(wav_np)) * noise_level * std\n",
        "            return wav_np + noise\n",
        "        return wav.cpu().numpy() if isinstance(wav, torch.Tensor) else wav\n",
        "\n",
        "    def __call__(self, wav):\n",
        "        if isinstance(wav, np.ndarray):\n",
        "            wav_torch = torch.from_numpy(wav).float()\n",
        "        else:\n",
        "            wav_torch = wav.float()\n",
        "\n",
        "        wav_torch = wav_torch.unsqueeze(0).unsqueeze(0)\n",
        "        augmented = self.augment(wav_torch, sample_rate=self.sample_rate)\n",
        "        augmented = augmented.squeeze(0).squeeze(0)\n",
        "        augmented_np = augmented.cpu().numpy()\n",
        "\n",
        "        if self.use_heavy_aug:\n",
        "            augmented_np = self.apply_time_stretch(augmented_np, rate=0.15)\n",
        "            augmented_np = self.apply_pitch_shift(augmented_np, n_steps_range=(-1.5, 1.5))\n",
        "            augmented_np = self.apply_background_noise(augmented_np, noise_level_range=(0.01, 0.04))\n",
        "\n",
        "        return augmented_np.astype(np.float32)\n",
        "\n",
        "augmentation = AudioAugmentation(sample_rate=16000, use_heavy_aug=True)"
      ],
      "metadata": {
        "id": "cmUA4UBdjf86"
      },
      "id": "cmUA4UBdjf86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "yppZ81syjtpe"
      },
      "id": "yppZ81syjtpe"
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'openai/whisper-medium'"
      ],
      "metadata": {
        "id": "ByicLs5zkDPc"
      },
      "id": "ByicLs5zkDPc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KWSDataset(Dataset):\n",
        "    def __init__(self, items, labels=None, sampling_rate=16000, augment=False):\n",
        "        self.processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        self.filepaths = [item[1] for item in items]\n",
        "        if labels is None:\n",
        "            self.labels = [0] * len(items)\n",
        "        else:\n",
        "            self.labels = labels\n",
        "\n",
        "        self.sampling_rate = sampling_rate\n",
        "        self.augment = augment\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        waveform, sr = torchaudio.load(self.filepaths[idx])\n",
        "        if sr != self.sampling_rate:\n",
        "            waveform = torchaudio.functional.resample(waveform, sr, self.sampling_rate)\n",
        "\n",
        "        if self.augment:\n",
        "            waveform_np = augmentation(waveform.squeeze(0).numpy())\n",
        "            waveform = torch.from_numpy(waveform_np).unsqueeze(0)\n",
        "\n",
        "        inputs = self.processor(\n",
        "            waveform.squeeze(0),\n",
        "            sampling_rate=self.sampling_rate,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        inputs_dict = {\"input_features\": inputs.input_features.squeeze(0)}\n",
        "        if self.labels is not None:\n",
        "            inputs_dict[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return inputs_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)"
      ],
      "metadata": {
        "id": "6o6hNRj1j5Fo"
      },
      "id": "6o6hNRj1j5Fo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [1] * len(pos_train) + [0] * len(neg_train)\n",
        "val_labels = [1] * len(pos_val) + [0] * len(neg_val)\n",
        "\n",
        "train_dataset = KWSDataset(train_items, train_labels, augment=True)\n",
        "val_dataset = KWSDataset(val_items, val_labels, augment=False)\n",
        "\n",
        "batch_size = 2\n",
        "gradient_accumulation_steps = 8\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "pKmIiegAnRV_"
      },
      "id": "pKmIiegAnRV_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model & training utils"
      ],
      "metadata": {
        "id": "VPr5NJqWn4rM"
      },
      "id": "VPr5NJqWn4rM"
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(preds, labels, num_pos, num_neg):\n",
        "    correct = (preds == labels).sum()\n",
        "    total = len(labels)\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    tp = ((preds == 1) & (labels == 1)).sum()\n",
        "    fp = ((preds == 1) & (labels == 0)).sum()\n",
        "    fn = ((preds == 0) & (labels == 1)).sum()\n",
        "    tn = ((preds == 0) & (labels == 0)).sum()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    frr = fn / num_pos if num_pos > 0 else 0\n",
        "    far = fp / num_neg if num_neg > 0 else 0\n",
        "\n",
        "    score_1_frr = 1 - frr\n",
        "    score_1_far = 1 - far\n",
        "\n",
        "    if score_1_frr > 0 and score_1_far > 0:\n",
        "        competition_score = hmean([score_1_frr, score_1_far])\n",
        "    else:\n",
        "        competition_score = 0.0\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'competition_score': competition_score,\n",
        "        'tp': tp,\n",
        "        'fp': fp,\n",
        "        'fn': fn,\n",
        "        'tn': tn\n",
        "    }"
      ],
      "metadata": {
        "id": "ELKBXyEeoAIk"
      },
      "id": "ELKBXyEeoAIk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataloader, criterion, device, num_pos, num_neg):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_features = batch['input_features'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_features, labels=labels)\n",
        "            loss = outputs['loss']\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = outputs['logits'].argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    metrics = calculate_metrics(all_preds, all_labels, num_pos, num_neg)\n",
        "    metrics['loss'] = total_loss / len(dataloader)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "phESl3izoCxG"
      },
      "id": "phESl3izoCxG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class AttentionPooling(nn.Module):\n",
        "#     def __init__(self, hidden_size):\n",
        "#         super().__init__()\n",
        "#         self.attention = nn.Sequential(\n",
        "#             nn.Linear(hidden_size, hidden_size // 2),\n",
        "#             nn.Tanh(),\n",
        "#             nn.Linear(hidden_size // 2, 1)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, hidden_states):\n",
        "#         attention_weights = self.attention(hidden_states)\n",
        "#         attention_weights = F.softmax(attention_weights, dim=1)\n",
        "#         pooled = torch.sum(hidden_states * attention_weights, dim=1)\n",
        "#         return pooled"
      ],
      "metadata": {
        "id": "Wsnf_ipWoJCX"
      },
      "id": "Wsnf_ipWoJCX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WhisperForKWS(nn.Module):\n",
        "    def __init__(self, model_id, num_labels=2):\n",
        "        super().__init__()\n",
        "        from transformers import AutoModelForSpeechSeq2Seq\n",
        "        self.whisper = AutoModelForSpeechSeq2Seq.from_pretrained(model_id)\n",
        "        hidden_size = self.whisper.model.encoder.layer_norm.normalized_shape[0]\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_size, 192),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(192, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_features, labels=None):\n",
        "        encoder_outputs = self.whisper.model.encoder(input_features)\n",
        "        hidden_states = encoder_outputs.last_hidden_state\n",
        "\n",
        "        pooled = hidden_states.mean(dim=1)\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ],
      "metadata": {
        "id": "Z2_Ze2sgoM8s"
      },
      "id": "Z2_Ze2sgoM8s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "AyxQGCzR0m9a"
      },
      "id": "AyxQGCzR0m9a"
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "4jblYwparqjS"
      },
      "id": "4jblYwparqjS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "\n",
        "model = WhisperForKWS(MODEL_NAME)\n",
        "model.to(device=device, dtype=torch.float32)\n",
        "\n",
        "whisper_lr = 1e-5\n",
        "classifier_lr = 25e-5\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.whisper.parameters(), 'lr': whisper_lr},\n",
        "    {'params': model.classifier.parameters(), 'lr': classifier_lr}\n",
        "])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "checkpoint_dir = 'whisper_checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "history = {\n",
        "    'train_loss': [], 'train_acc': [], 'train_f1': [], 'train_score': [],\n",
        "    'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_score': []\n",
        "}\n",
        "\n",
        "best_score = 0\n",
        "best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f'\\nEpoch {epoch}/{num_epochs}')\n",
        "\n",
        "    model.train()\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "    train_losses = []\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Training\")\n",
        "    for step, batch in enumerate(progress_bar):\n",
        "        input_features = batch['input_features'].to(device=device, dtype=torch.float32)\n",
        "        labels = batch['labels'].to(device=device)\n",
        "\n",
        "        outputs = model(input_features, labels=labels)\n",
        "        loss = outputs['loss'] / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        preds = outputs['logits'].argmax(dim=1).detach().cpu().numpy()\n",
        "        train_preds.extend(preds)\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "        train_losses.append(loss.item() * gradient_accumulation_steps)\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item() * gradient_accumulation_steps)\n",
        "\n",
        "    if len(train_loader) % gradient_accumulation_steps != 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    train_metrics = calculate_metrics(np.array(train_preds), np.array(train_labels), len(pos_train), len(neg_train))\n",
        "    train_metrics['loss'] = np.mean(train_losses)\n",
        "\n",
        "    val_metrics = validate(model, val_loader, criterion, device, len(pos_val), len(neg_val))\n",
        "\n",
        "    history['train_loss'].append(train_metrics['loss'])\n",
        "    history['train_acc'].append(train_metrics['accuracy'])\n",
        "    history['train_f1'].append(train_metrics['f1'])\n",
        "    history['train_score'].append(train_metrics['competition_score'])\n",
        "    history['val_loss'].append(val_metrics['loss'])\n",
        "    history['val_acc'].append(val_metrics['accuracy'])\n",
        "    history['val_f1'].append(val_metrics['f1'])\n",
        "    history['val_score'].append(val_metrics['competition_score'])\n",
        "\n",
        "    print(f\"Train Loss: {train_metrics['loss']:.4f} | Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f} | Score: {train_metrics['competition_score']:.4f}\")\n",
        "    print(f\"Val Loss: {val_metrics['loss']:.4f} | Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f} | Score: {val_metrics['competition_score']:.4f}\")\n",
        "\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch}.pth')\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "    if val_metrics['competition_score'] > best_score:\n",
        "        best_score = val_metrics['competition_score']\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f'Best model saved with Score: {best_score:.4f}')\n",
        "\n",
        "print(f'Best validation Score: {best_score:.4f}')"
      ],
      "metadata": {
        "id": "usMSGxpGotT3"
      },
      "id": "usMSGxpGotT3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making submission"
      ],
      "metadata": {
        "id": "lKjEHmlX0q2s"
      },
      "id": "lKjEHmlX0q2s"
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(best_model_path))"
      ],
      "metadata": {
        "id": "dwG1OM2m0vaO"
      },
      "id": "dwG1OM2m0vaO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_probs = []\n",
        "val_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch in tqdm(val_loader):\n",
        "        input_features = batch['input_features'].to(device=device, dtype=torch.float32)\n",
        "        labels = batch['labels'].to(device=device)\n",
        "        outputs = model(input_features)\n",
        "        val_probs.extend(outputs['logits'].softmax(dim=-1)[:, 1].cpu().numpy())\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "val_probs = np.array(val_probs)\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "3stoxQWl2mwH"
      },
      "id": "3stoxQWl2mwH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(0.1, 0.9, 0.025)\n",
        "best_score = 0\n",
        "best_threshold = 0.5\n",
        "\n",
        "for thresh in thresholds:\n",
        "    preds = (val_probs >= thresh).astype(int)\n",
        "    metrics = calculate_metrics(preds, val_labels, len(pos_val), len(neg_val))\n",
        "    if metrics['competition_score'] > best_score:\n",
        "        best_score = metrics['competition_score']\n",
        "        best_threshold = thresh\n",
        "\n",
        "print(f'Best threshold: {best_threshold:.2f} with score: {best_score:.4f}')"
      ],
      "metadata": {
        "id": "zvN9TJW32xJv"
      },
      "id": "zvN9TJW32xJv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_filepaths = os.listdir(test_audio_path)\n",
        "test_ids = [f.replace('.opus', '') for f in test_filepaths]\n",
        "test_audio_paths = [f'{test_audio_path}/{f}' for f in test_filepaths]\n",
        "test_items = [[id, path] for id, path in zip(test_ids, test_audio_paths)]\n",
        "\n",
        "test_dataset = KWSDataset(test_items)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True)\n",
        "\n",
        "probs = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch in tqdm(test_loader):\n",
        "        input_features = batch['input_features'].to(device=device, dtype=torch.float32)\n",
        "        outputs = model(input_features)\n",
        "        probs.append(outputs['logits'].softmax(dim=-1).cpu().numpy())\n",
        "\n",
        "probs = np.concatenate(probs, axis=0)"
      ],
      "metadata": {
        "id": "D0ZeaItp3-Wp"
      },
      "id": "D0ZeaItp3-Wp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = (probs[:, 1] >= best_threshold).astype(int)\n",
        "submission = pd.DataFrame({'id': test_ids, 'label': test_labels})\n",
        "submission.label.value_counts(normalize=True)\n",
        "\n",
        "submission.to_csv(f\"sub-mean-seed-{SEED}.csv\", index=False)\n",
        "submission.head()"
      ],
      "metadata": {
        "id": "xpzTi5Rh0rUs"
      },
      "id": "xpzTi5Rh0rUs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}