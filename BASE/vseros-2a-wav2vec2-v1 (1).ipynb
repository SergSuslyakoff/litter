{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4349c7",
   "metadata": {
    "_cell_guid": "94b12b78-f65c-40dd-a393-519a01b35657",
    "_uuid": "8289e528-a30c-461a-ab13-e051a291dd63",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.007991,
     "end_time": "2025-10-18T16:08:58.498777",
     "exception": false,
     "start_time": "2025-10-18T16:08:58.490786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. работа с данными - вырезаем куски с key word, sliding иференс на test и тд (так то уже есть в бейзлайне), преобразование в логмелспектрограммы (через processor модели) + аугментации на train\n",
    "2. сплит на train/val + подсчет кастомной метрики во время обучения\n",
    "3. берем мощный трансформер wav2vec2 (енкодер + классификатор) с простой кросс ентропией должно обучиться норм, а дальше докрутить\n",
    "4. блендинг/стекинг + подбор порогов на валидации/лб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835cb96a",
   "metadata": {
    "_cell_guid": "b5526d7b-31f2-4645-a0f8-2ed4f3349781",
    "_uuid": "fb29603a-f713-4793-a6da-71ab45920690",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:08:58.513432Z",
     "iopub.status.busy": "2025-10-18T16:08:58.513163Z",
     "iopub.status.idle": "2025-10-18T16:10:43.112910Z",
     "shell.execute_reply": "2025-10-18T16:10:43.111628Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 104.60878,
     "end_time": "2025-10-18T16:10:43.114549",
     "exception": false,
     "start_time": "2025-10-18T16:08:58.505769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 16:09:17.283692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760803757.473975      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760803757.530277      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mUsing device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "\n",
    "!pip -q install torch-audiomentations\n",
    "from torch_audiomentations import Compose, Gain, PolarityInversion, AddColoredNoise, Shift, HighPassFilter, LowPassFilter\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6dad58",
   "metadata": {
    "_cell_guid": "e29a49d8-c4be-40b7-9d13-7e0a7897a411",
    "_uuid": "414f7d56-e556-449e-9ac9-54c4fd7e834c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:43.172555Z",
     "iopub.status.busy": "2025-10-18T16:10:43.170858Z",
     "iopub.status.idle": "2025-10-18T16:10:43.182420Z",
     "shell.execute_reply": "2025-10-18T16:10:43.181772Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.041699,
     "end_time": "2025-10-18T16:10:43.184015",
     "exception": false,
     "start_time": "2025-10-18T16:10:43.142316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7033abe",
   "metadata": {
    "_cell_guid": "1e9ec17d-963c-488a-9f27-0d39b151067c",
    "_uuid": "9a19057a-6c52-4dc5-97c3-15dd833522bc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026791,
     "end_time": "2025-10-18T16:10:43.238221",
     "exception": false,
     "start_time": "2025-10-18T16:10:43.211430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567efdc9",
   "metadata": {
    "_cell_guid": "518740b8-f1ef-40d4-a281-f34f17bed258",
    "_uuid": "7358c926-dcaf-47aa-88e5-e60f7cc74bb7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:43.293805Z",
     "iopub.status.busy": "2025-10-18T16:10:43.293444Z",
     "iopub.status.idle": "2025-10-18T16:10:43.297203Z",
     "shell.execute_reply": "2025-10-18T16:10:43.296392Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.03301,
     "end_time": "2025-10-18T16:10:43.298477",
     "exception": false,
     "start_time": "2025-10-18T16:10:43.265467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_audio_path = '/kaggle/input/vseros-2a/train_audio/train_audio'\n",
    "test_audio_path = '/kaggle/input/vseros-2a/test_audio/test_audio'\n",
    "word_bounds_path = '/kaggle/input/vseros-2a/word_bounds.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a61b51",
   "metadata": {
    "_cell_guid": "c8e76f6d-118c-4abb-a9c6-a08bcb14c5d6",
    "_uuid": "1b6cbb0e-abd6-48a8-b19c-bd8cf2dfaa5a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:43.354008Z",
     "iopub.status.busy": "2025-10-18T16:10:43.353193Z",
     "iopub.status.idle": "2025-10-18T16:10:50.281519Z",
     "shell.execute_reply": "2025-10-18T16:10:50.280466Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.957748,
     "end_time": "2025-10-18T16:10:50.283150",
     "exception": false,
     "start_time": "2025-10-18T16:10:43.325402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 90000\n",
      "Test files: 27000\n",
      "Word bounds entries: 45000\n",
      "Positive samples: 45000 (50.0%)\n",
      "Negative samples: 45000 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "train_files = sorted(list(Path(train_audio_path).glob('*.opus')))\n",
    "test_files = sorted(list(Path(test_audio_path).glob('*.opus')))\n",
    "\n",
    "with open(word_bounds_path, 'r') as f:\n",
    "    word_bounds = json.load(f)\n",
    "\n",
    "print(f'Train files: {len(train_files)}')\n",
    "print(f'Test files: {len(test_files)}')\n",
    "print(f'Word bounds entries: {len(word_bounds)}')\n",
    "\n",
    "pos_count = len([f for f in train_files if f.stem in word_bounds])\n",
    "neg_count = len(train_files) - pos_count\n",
    "print(f'Positive samples: {pos_count} ({pos_count/len(train_files)*100:.1f}%)')\n",
    "print(f'Negative samples: {neg_count} ({neg_count/len(train_files)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dd280b",
   "metadata": {
    "_cell_guid": "91cdc437-741d-4bba-af9e-6972d0aa6b89",
    "_uuid": "d2a400b2-806e-49d0-8bd3-4542fa5e7975",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:50.340620Z",
     "iopub.status.busy": "2025-10-18T16:10:50.340320Z",
     "iopub.status.idle": "2025-10-18T16:10:50.669459Z",
     "shell.execute_reply": "2025-10-18T16:10:50.668572Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.360066,
     "end_time": "2025-10-18T16:10:50.671178",
     "exception": false,
     "start_time": "2025-10-18T16:10:50.311112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 81000 (pos: 40500, neg: 40500)\n",
      "Val: 9000 (pos: 4500, neg: 4500)\n"
     ]
    }
   ],
   "source": [
    "pos_items = []\n",
    "neg_items = []\n",
    "\n",
    "for fpath in train_files:\n",
    "    fid = fpath.stem\n",
    "    if fid in word_bounds:\n",
    "        start, end = word_bounds[fid]\n",
    "        pos_items.append((str(fpath), float(start), float(end)))\n",
    "    else:\n",
    "        neg_items.append((str(fpath), None, None))\n",
    "\n",
    "val_split = 0.1\n",
    "pos_train, pos_val = train_test_split(pos_items, test_size=val_split, random_state=42)\n",
    "neg_train, neg_val = train_test_split(neg_items, test_size=val_split, random_state=42)\n",
    "\n",
    "train_items = pos_train + neg_train\n",
    "val_items = pos_val + neg_val\n",
    "\n",
    "random.shuffle(train_items)\n",
    "random.shuffle(val_items)\n",
    "\n",
    "print(f'Train: {len(train_items)} (pos: {len(pos_train)}, neg: {len(neg_train)})')\n",
    "print(f'Val: {len(val_items)} (pos: {len(pos_val)}, neg: {len(neg_val)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd275b0",
   "metadata": {
    "_cell_guid": "aa1f19ac-7c1d-4a5a-a2b2-a703a68f82d0",
    "_uuid": "1296e326-8b9f-4b2e-9fca-a1aa803ce10f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027353,
     "end_time": "2025-10-18T16:10:50.727223",
     "exception": false,
     "start_time": "2025-10-18T16:10:50.699870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Audio utils & augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9b8bd9",
   "metadata": {
    "_cell_guid": "d0b0eb20-94da-436f-9041-09d83a5e4ea9",
    "_uuid": "74ec4be4-10ad-4c98-81e8-6014e1746611",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:50.783079Z",
     "iopub.status.busy": "2025-10-18T16:10:50.782779Z",
     "iopub.status.idle": "2025-10-18T16:10:50.795398Z",
     "shell.execute_reply": "2025-10-18T16:10:50.794482Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.042732,
     "end_time": "2025-10-18T16:10:50.796812",
     "exception": false,
     "start_time": "2025-10-18T16:10:50.754080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_audio(path: str, sr: int = 16000) -> np.ndarray:\n",
    "    try:\n",
    "        wav, orig_sr = torchaudio.load(path)\n",
    "        if wav.size(0) > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        wav = wav.squeeze(0)\n",
    "        if orig_sr != sr:\n",
    "            wav = torchaudio.functional.resample(wav, orig_sr, sr)\n",
    "        wav = wav.numpy()\n",
    "    except:\n",
    "        try:\n",
    "            wav, orig_sr = librosa.load(path, sr=sr, mono=True)\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {path}: {e}')\n",
    "            return np.zeros(sr, dtype=np.float32)\n",
    "    \n",
    "    return wav.astype(np.float32)\n",
    "\n",
    "def normalize_audio(wav: np.ndarray, method='peak') -> np.ndarray:\n",
    "    if method == 'peak':\n",
    "        peak = np.abs(wav).max()\n",
    "        if peak > 1e-8:\n",
    "            wav = wav / peak\n",
    "    elif method == 'rms':\n",
    "        rms = np.sqrt(np.mean(wav ** 2))\n",
    "        if rms > 1e-8:\n",
    "            wav = wav / (rms * 10)\n",
    "            wav = np.clip(wav, -1, 1)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a3c1dc",
   "metadata": {
    "_cell_guid": "bbf43963-6ad2-4220-bb5c-c3ddf93f3c78",
    "_uuid": "f9ad5319-2b6e-4843-a30d-20df15ada433",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:50.853252Z",
     "iopub.status.busy": "2025-10-18T16:10:50.852760Z",
     "iopub.status.idle": "2025-10-18T16:10:50.864744Z",
     "shell.execute_reply": "2025-10-18T16:10:50.863912Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.040805,
     "end_time": "2025-10-18T16:10:50.865992",
     "exception": false,
     "start_time": "2025-10-18T16:10:50.825187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioAugmentation:\n",
    "    def __init__(self, sample_rate=16000):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        self.augment = Compose(\n",
    "            transforms=[\n",
    "                Gain(min_gain_in_db=-15.0, max_gain_in_db=5.0, p=0.5),\n",
    "                PolarityInversion(p=0.5),\n",
    "                AddColoredNoise(min_snr_in_db=5.0, max_snr_in_db=30.0, min_f_decay=-2.0, max_f_decay=2.0, p=0.5),\n",
    "                Shift(min_shift=-0.5, max_shift=0.5, shift_unit=\"fraction\", rollover=True, p=0.5),\n",
    "                HighPassFilter(min_cutoff_freq=20.0, max_cutoff_freq=400.0, p=0.3),\n",
    "                LowPassFilter(min_cutoff_freq=2000.0, max_cutoff_freq=7500.0, p=0.3),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def __call__(self, wav):\n",
    "        if isinstance(wav, np.ndarray):\n",
    "            wav = torch.from_numpy(wav).float()\n",
    "        \n",
    "        wav = wav.unsqueeze(0).unsqueeze(0)\n",
    "        augmented = self.augment(wav, sample_rate=self.sample_rate)\n",
    "        augmented = augmented.squeeze(0).squeeze(0)\n",
    "        \n",
    "        if isinstance(augmented, torch.Tensor):\n",
    "            augmented = augmented.numpy()\n",
    "        \n",
    "        return augmented.astype(np.float32)\n",
    "\n",
    "augmentation = AudioAugmentation(sample_rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e0b3a",
   "metadata": {
    "_cell_guid": "5e230452-d6ea-450e-a77f-cb2f739c60d9",
    "_uuid": "0af9b50e-b0d1-447a-a36d-03c788378b06",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.0263,
     "end_time": "2025-10-18T16:10:50.918383",
     "exception": false,
     "start_time": "2025-10-18T16:10:50.892083",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Datasets & utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034eb226",
   "metadata": {
    "_cell_guid": "2e9f413e-30ba-4860-ad4e-69b5860f567b",
    "_uuid": "2d59960e-4880-44e2-93f9-1998163a01d7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:50.974168Z",
     "iopub.status.busy": "2025-10-18T16:10:50.973587Z",
     "iopub.status.idle": "2025-10-18T16:10:50.983589Z",
     "shell.execute_reply": "2025-10-18T16:10:50.982980Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038673,
     "end_time": "2025-10-18T16:10:50.984833",
     "exception": false,
     "start_time": "2025-10-18T16:10:50.946160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KWSDataset(Dataset):\n",
    "    def __init__(self, items, segment_samples, sr=16000, augment=None):\n",
    "        self.items = items\n",
    "        self.segment_samples = segment_samples\n",
    "        self.sr = sr\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def extract_positive_segment(self, wav, start_sec, end_sec):\n",
    "        start_idx = int(start_sec * self.sr)\n",
    "        end_idx = int(end_sec * self.sr)\n",
    "        \n",
    "        phrase_len = end_idx - start_idx\n",
    "        \n",
    "        if phrase_len >= self.segment_samples:\n",
    "            center = (start_idx + end_idx) // 2\n",
    "            left = max(0, center - self.segment_samples // 2)\n",
    "            right = min(len(wav), left + self.segment_samples)\n",
    "            left = right - self.segment_samples\n",
    "        else:\n",
    "            context_total = self.segment_samples - phrase_len\n",
    "            context_left = random.randint(0, context_total)\n",
    "            context_right = context_total - context_left\n",
    "            \n",
    "            left = max(0, start_idx - context_left)\n",
    "            right = min(len(wav), end_idx + context_right)\n",
    "            \n",
    "            if right - left < self.segment_samples:\n",
    "                if left == 0:\n",
    "                    right = min(len(wav), left + self.segment_samples)\n",
    "                else:\n",
    "                    left = max(0, right - self.segment_samples)\n",
    "        \n",
    "        segment = wav[left:right]\n",
    "        \n",
    "        if len(segment) < self.segment_samples:\n",
    "            pad = self.segment_samples - len(segment)\n",
    "            segment = np.pad(segment, (0, pad), mode='constant')\n",
    "        elif len(segment) > self.segment_samples:\n",
    "            segment = segment[:self.segment_samples]\n",
    "        \n",
    "        return segment\n",
    "    \n",
    "    def extract_negative_segment(self, wav):\n",
    "        if len(wav) <= self.segment_samples:\n",
    "            segment = wav\n",
    "            if len(segment) < self.segment_samples:\n",
    "                pad = self.segment_samples - len(segment)\n",
    "                segment = np.pad(segment, (0, pad), mode='constant')\n",
    "        else:\n",
    "            start = random.randint(0, len(wav) - self.segment_samples)\n",
    "            segment = wav[start:start + self.segment_samples]\n",
    "        \n",
    "        return segment\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, start_sec, end_sec = self.items[idx]\n",
    "        \n",
    "        wav = load_audio(path, self.sr)\n",
    "        wav = normalize_audio(wav)\n",
    "        \n",
    "        label = 1 if start_sec is not None else 0\n",
    "        \n",
    "        if label == 1:\n",
    "            segment = self.extract_positive_segment(wav, start_sec, end_sec)\n",
    "        else:\n",
    "            segment = self.extract_negative_segment(wav)\n",
    "        \n",
    "        if self.augment is not None:\n",
    "            segment = self.augment(segment)\n",
    "        \n",
    "        segment = normalize_audio(segment)\n",
    "        \n",
    "        return segment, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092fa9f2",
   "metadata": {
    "_cell_guid": "468f418d-4209-42ba-8fd2-8acfa74f7ed9",
    "_uuid": "b5c23125-412a-4bb1-95fc-3abe7e537cb0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:51.039156Z",
     "iopub.status.busy": "2025-10-18T16:10:51.038874Z",
     "iopub.status.idle": "2025-10-18T16:10:51.046052Z",
     "shell.execute_reply": "2025-10-18T16:10:51.045223Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035831,
     "end_time": "2025-10-18T16:10:51.047314",
     "exception": false,
     "start_time": "2025-10-18T16:10:51.011483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KWSTestDatasetWindowed(Dataset):\n",
    "    def __init__(self, file_paths, window_samples, hop_samples, sr=16000):\n",
    "        self.file_paths = file_paths\n",
    "        self.window_samples = window_samples\n",
    "        self.hop_samples = hop_samples\n",
    "        self.sr = sr\n",
    "        \n",
    "        self.samples = []\n",
    "        \n",
    "        print(\"Preparing test windows...\")\n",
    "        for path in tqdm(file_paths):\n",
    "            file_id = Path(path).stem\n",
    "            wav = load_audio(path, sr)\n",
    "            wav = normalize_audio(wav)\n",
    "            \n",
    "            if len(wav) <= window_samples:\n",
    "                if len(wav) < window_samples:\n",
    "                    pad = window_samples - len(wav)\n",
    "                    wav = np.pad(wav, (0, pad), mode='constant')\n",
    "                self.samples.append((wav, file_id, 0))\n",
    "            else:\n",
    "                num_windows = (len(wav) - window_samples) // hop_samples + 1\n",
    "                \n",
    "                for i in range(num_windows):\n",
    "                    start = i * hop_samples\n",
    "                    end = start + window_samples\n",
    "                    \n",
    "                    if end > len(wav):\n",
    "                        start = len(wav) - window_samples\n",
    "                        end = len(wav)\n",
    "                    \n",
    "                    segment = wav[start:end]\n",
    "                    self.samples.append((segment, file_id, i))\n",
    "                    \n",
    "                    if end >= len(wav):\n",
    "                        break\n",
    "        \n",
    "        print(f\"Total windows created: {len(self.samples)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        segment, file_id, window_idx = self.samples[idx]\n",
    "        return segment, file_id, window_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2b522be",
   "metadata": {
    "_cell_guid": "1b9ee85e-a636-495c-8b1a-71effa3cb9ff",
    "_uuid": "09917cbf-1bdb-4379-b9f1-da0b03347020",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:51.102310Z",
     "iopub.status.busy": "2025-10-18T16:10:51.102028Z",
     "iopub.status.idle": "2025-10-18T16:10:51.629680Z",
     "shell.execute_reply": "2025-10-18T16:10:51.628933Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.556598,
     "end_time": "2025-10-18T16:10:51.630860",
     "exception": false,
     "start_time": "2025-10-18T16:10:51.074262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5f238c99af49108a20ea4f1d4e6c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'UrukHan/wav2vec2-russian'\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def collate_train_val(batch):\n",
    "    wavs, labels = zip(*batch)\n",
    "    \n",
    "    inputs = feature_extractor(\n",
    "        list(wavs),\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        max_length=24000,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return inputs.input_values, labels\n",
    "\n",
    "def collate_test_windows(batch):\n",
    "    segments, file_ids, window_indices = zip(*batch)\n",
    "    \n",
    "    inputs = feature_extractor(\n",
    "        list(segments),\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        max_length=24000,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    return inputs.input_values, list(file_ids), list(window_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba5695d",
   "metadata": {
    "_cell_guid": "24975bd6-14d9-4035-84fe-1eea216e0b4c",
    "_uuid": "4a5a2113-a0b0-42a0-9cda-67b63653c332",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:51.687221Z",
     "iopub.status.busy": "2025-10-18T16:10:51.686916Z",
     "iopub.status.idle": "2025-10-18T16:10:51.693584Z",
     "shell.execute_reply": "2025-10-18T16:10:51.692694Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036251,
     "end_time": "2025-10-18T16:10:51.694894",
     "exception": false,
     "start_time": "2025-10-18T16:10:51.658643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 10125\n",
      "Val batches: 1125\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 16000\n",
    "segment_duration = 1.5\n",
    "segment_samples = int(sample_rate * segment_duration)\n",
    "\n",
    "train_dataset = KWSDataset(\n",
    "    train_items, \n",
    "    segment_samples=segment_samples,\n",
    "    sr=sample_rate,\n",
    "    augment=augmentation\n",
    ")\n",
    "\n",
    "val_dataset = KWSDataset(\n",
    "    val_items,\n",
    "    segment_samples=segment_samples,\n",
    "    sr=sample_rate,\n",
    "    augment=None\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_train_val,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_train_val,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89992b54",
   "metadata": {
    "_cell_guid": "842bf52c-6cd9-4979-89ff-ec6dd722f8e9",
    "_uuid": "9f052809-e74a-4215-a0e3-ec242b7e4afc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:10:51.750469Z",
     "iopub.status.busy": "2025-10-18T16:10:51.750208Z",
     "iopub.status.idle": "2025-10-18T16:21:48.057022Z",
     "shell.execute_reply": "2025-10-18T16:21:48.056151Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 656.335981,
     "end_time": "2025-10-18T16:21:48.058330",
     "exception": false,
     "start_time": "2025-10-18T16:10:51.722349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test windows...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5e50c8e5554a1a8b6e5e8c97a83da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 162000\n",
      "Test batches: 20250\n"
     ]
    }
   ],
   "source": [
    "test_window_duration = 1.5\n",
    "test_window_samples = int(sample_rate * test_window_duration)\n",
    "test_hop_duration = 0.5\n",
    "test_hop_samples = int(sample_rate * test_hop_duration)\n",
    "\n",
    "test_dataset_windowed = KWSTestDatasetWindowed(\n",
    "    [str(f) for f in test_files],\n",
    "    window_samples=test_window_samples,\n",
    "    hop_samples=test_hop_samples,\n",
    "    sr=sample_rate\n",
    ")\n",
    "\n",
    "test_loader_windowed = DataLoader(\n",
    "    test_dataset_windowed,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_test_windows,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "print(f'Test batches: {len(test_loader_windowed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092ac34",
   "metadata": {
    "_cell_guid": "eea4b3dd-5786-4735-b28f-fd97a4b608e7",
    "_uuid": "9f12d49c-8ad0-43f0-bf8d-1b96d91fe774",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026644,
     "end_time": "2025-10-18T16:21:48.114544",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.087900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model & training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3529f090",
   "metadata": {
    "_cell_guid": "c27d3225-39a6-491c-ba20-0976bc52bbb5",
    "_uuid": "9e59cd34-72aa-4005-a3ad-3ca83e3b7877",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:48.168387Z",
     "iopub.status.busy": "2025-10-18T16:21:48.168106Z",
     "iopub.status.idle": "2025-10-18T16:21:48.174992Z",
     "shell.execute_reply": "2025-10-18T16:21:48.174333Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035207,
     "end_time": "2025-10-18T16:21:48.176122",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.140915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, labels, num_pos, num_neg):\n",
    "    correct = (preds == labels).sum()\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    tp = ((preds == 1) & (labels == 1)).sum()\n",
    "    fp = ((preds == 1) & (labels == 0)).sum()\n",
    "    fn = ((preds == 0) & (labels == 1)).sum()\n",
    "    tn = ((preds == 0) & (labels == 0)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    frr = fn / num_pos if num_pos > 0 else 0\n",
    "    far = fp / num_neg if num_neg > 0 else 0\n",
    "    \n",
    "    score_1_frr = 1 - frr\n",
    "    score_1_far = 1 - far\n",
    "    \n",
    "    if score_1_frr > 0 and score_1_far > 0:\n",
    "        competition_score = hmean([score_1_frr, score_1_far])\n",
    "    else:\n",
    "        competition_score = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'competition_score': competition_score,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5785277c",
   "metadata": {
    "_cell_guid": "f0f70cc6-fb4e-4f01-a4db-3d950264ccfc",
    "_uuid": "60416e11-e927-4a9f-9402-a098825ad3b6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:48.231560Z",
     "iopub.status.busy": "2025-10-18T16:21:48.231304Z",
     "iopub.status.idle": "2025-10-18T16:21:48.238930Z",
     "shell.execute_reply": "2025-10-18T16:21:48.238365Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.037163,
     "end_time": "2025-10-18T16:21:48.240106",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.202943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_epoch(model, loader, optimizer, criterion, device, num_pos, num_neg):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "    \n",
    "#     pbar = tqdm(loader, desc='Training', leave=False)\n",
    "#     for input_values, labels in pbar:\n",
    "#         input_values = input_values.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         logits = model(input_values)\n",
    "#         loss = criterion(logits, labels)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "        \n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "#         all_preds.extend(preds.cpu().numpy())\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "#         pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "#     avg_loss = total_loss / len(loader)\n",
    "#     all_preds = np.array(all_preds)\n",
    "#     all_labels = np.array(all_labels)\n",
    "#     metrics = calculate_metrics(all_preds, all_labels, num_pos, num_neg)\n",
    "#     metrics['loss'] = avg_loss\n",
    "    \n",
    "#     return metrics\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device, num_pos, num_neg, accumulation_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    for batch_idx, (input_values, labels) in enumerate(pbar):\n",
    "        input_values = input_values.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logits = model(input_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss = loss / accumulation_steps  # нормализуем лосс\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item() * accumulation_steps:.4f}'})\n",
    "    \n",
    "    if (batch_idx + 1) % accumulation_steps != 0:\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    metrics = calculate_metrics(all_preds, all_labels, num_pos, num_neg)\n",
    "    metrics['loss'] = avg_loss\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4709a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:48.296087Z",
     "iopub.status.busy": "2025-10-18T16:21:48.295797Z",
     "iopub.status.idle": "2025-10-18T16:21:48.301789Z",
     "shell.execute_reply": "2025-10-18T16:21:48.301132Z"
    },
    "papermill": {
     "duration": 0.035078,
     "end_time": "2025-10-18T16:21:48.302998",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.267920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion, device, num_pos, num_neg):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Validation', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for input_values, labels in pbar:\n",
    "            input_values = input_values.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits = model(input_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    metrics = calculate_metrics(all_preds, all_labels, num_pos, num_neg)\n",
    "    metrics['loss'] = avg_loss\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5580ebd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:48.358792Z",
     "iopub.status.busy": "2025-10-18T16:21:48.358461Z",
     "iopub.status.idle": "2025-10-18T16:21:48.362476Z",
     "shell.execute_reply": "2025-10-18T16:21:48.361678Z"
    },
    "papermill": {
     "duration": 0.033495,
     "end_time": "2025-10-18T16:21:48.363824",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.330329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AttentionPooling(nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super().__init__()\n",
    "#         self.attention = nn.Sequential(\n",
    "#             nn.Linear(hidden_size, hidden_size // 2),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(hidden_size // 2, 1)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, hidden_states):\n",
    "#         attention_weights = self.attention(hidden_states)\n",
    "#         attention_weights = F.softmax(attention_weights, dim=1)\n",
    "#         pooled = torch.sum(hidden_states * attention_weights, dim=1)\n",
    "#         return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "242fac92",
   "metadata": {
    "_cell_guid": "2a84e9d4-21b3-42e9-8751-729ca1dc1e0a",
    "_uuid": "32214b20-39e7-4078-b643-0f6740479886",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:48.420546Z",
     "iopub.status.busy": "2025-10-18T16:21:48.420058Z",
     "iopub.status.idle": "2025-10-18T16:21:48.426865Z",
     "shell.execute_reply": "2025-10-18T16:21:48.426012Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036411,
     "end_time": "2025-10-18T16:21:48.428139",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.391728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wav2Vec2ForKWS(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=2, freeze_feature_extractor=True, freeze_encoder_layers=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.wav2vec2 = Wav2Vec2Model.from_pretrained(model_name)\n",
    "        \n",
    "        if freeze_feature_extractor:\n",
    "            for param in self.wav2vec2.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        if freeze_encoder_layers > 0:\n",
    "            for layer in self.wav2vec2.encoder.layers[:freeze_encoder_layers]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        hidden_size = self.wav2vec2.config.hidden_size\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_labels)\n",
    "        )\n",
    "        \n",
    "        # for module in self.classifier.modules():\n",
    "        #     if isinstance(module, nn.Linear):\n",
    "        #         nn.init.normal_(module.weight, std=0.02)\n",
    "        #         nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, input_values):\n",
    "        outputs = self.wav2vec2(input_values)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        pooled = torch.mean(hidden_states, dim=1)\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3e9441",
   "metadata": {
    "_cell_guid": "fffc9488-2c6d-4f6c-aa1c-258cfc66a4d5",
    "_uuid": "27c8a240-556c-424d-8ba4-bd6a58cd6357",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026944,
     "end_time": "2025-10-18T16:21:48.482289",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.455345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8913b4a",
   "metadata": {
    "_cell_guid": "d08cbf09-166b-45bd-aa05-6946a7d95369",
    "_uuid": "b3ac214a-26fb-47e2-a4f4-71cbd76946b7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:48.537446Z",
     "iopub.status.busy": "2025-10-18T16:21:48.536881Z",
     "iopub.status.idle": "2025-10-18T16:21:57.846686Z",
     "shell.execute_reply": "2025-10-18T16:21:57.845808Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.339091,
     "end_time": "2025-10-18T16:21:57.848145",
     "exception": false,
     "start_time": "2025-10-18T16:21:48.509054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48aa7d5ce5874614bdc87eaa6170ca7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "392365f2cb954326908ebbbf7b5c3a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 315,734,274\n",
      "Trainable parameters: 84,792,066\n",
      "Trainable percentage: 0.27\n"
     ]
    }
   ],
   "source": [
    "freeze_feature_extractor = True\n",
    "freeze_encoder_layers = 18\n",
    "\n",
    "model = Wav2Vec2ForKWS(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    freeze_feature_extractor=freeze_feature_extractor,\n",
    "    freeze_encoder_layers=freeze_encoder_layers\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')\n",
    "print(f'Trainable percentage: {trainable_params / total_params:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f920dd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:57.905533Z",
     "iopub.status.busy": "2025-10-18T16:21:57.905248Z",
     "iopub.status.idle": "2025-10-18T16:21:57.912084Z",
     "shell.execute_reply": "2025-10-18T16:21:57.911207Z"
    },
    "papermill": {
     "duration": 0.036978,
     "end_time": "2025-10-18T16:21:57.913328",
     "exception": false,
     "start_time": "2025-10-18T16:21:57.876350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "learning_rate = 3e-4\n",
    "weight_decay = 0.01\n",
    "\n",
    "batch_size_effective = 64\n",
    "batch_size_actual = 8\n",
    "accumulation_steps = batch_size_effective // batch_size_actual  # = 8\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=num_epochs,\n",
    "    eta_min=5e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffbb6fb2",
   "metadata": {
    "_cell_guid": "deffc55f-c196-44db-980b-2626e174e633",
    "_uuid": "0288885f-9835-404e-9c64-7f0d2d0ba129",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:57.970346Z",
     "iopub.status.busy": "2025-10-18T16:21:57.969534Z",
     "iopub.status.idle": "2025-10-18T16:21:58.628846Z",
     "shell.execute_reply": "2025-10-18T16:21:58.628134Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.688788,
     "end_time": "2025-10-18T16:21:58.630174",
     "exception": false,
     "start_time": "2025-10-18T16:21:57.941386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f1ceb4f",
   "metadata": {
    "_cell_guid": "eb0ebc4c-9dde-4e06-bc2e-7f6cc8d6c2fb",
    "_uuid": "c36ce39c-de1c-4ca9-b31a-87cc42ddbcaa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T16:21:58.693860Z",
     "iopub.status.busy": "2025-10-18T16:21:58.693119Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.03204,
     "end_time": "2025-10-18T16:21:59.694176",
     "exception": false,
     "start_time": "2025-10-18T16:21:58.662136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1472a9d897495592f97cb5f2062c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_dir = MODEL_NAME[MODEL_NAME.find('/')+1:]\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [], 'train_f1': [], 'train_score': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_score': []\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "\n",
    "train_num_pos = len(pos_train)\n",
    "train_num_neg = len(neg_train)\n",
    "val_num_pos = len(pos_val)\n",
    "val_num_neg = len(neg_val)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    train_metrics = train_epoch(\n",
    "        model, train_loader, optimizer, criterion, device,\n",
    "        train_num_pos, train_num_neg,\n",
    "        accumulation_steps=accumulation_steps  # ДОБАВЛЕНО\n",
    "    )\n",
    "    val_metrics = validate(\n",
    "        model, val_loader, criterion, device,\n",
    "        val_num_pos, val_num_neg\n",
    "    )\n",
    "    \n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['train_acc'].append(train_metrics['accuracy'])\n",
    "    history['train_f1'].append(train_metrics['f1'])\n",
    "    history['train_score'].append(train_metrics['competition_score'])\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_acc'].append(val_metrics['accuracy'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    history['val_score'].append(val_metrics['competition_score'])\n",
    "    \n",
    "    print(f\"\\nTrain Metrics:\")\n",
    "    print(f\"  Loss: {train_metrics['loss']:.4f} | Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f}\")\n",
    "    print(f\"  Competition Score: {train_metrics['competition_score']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nVal Metrics:\")\n",
    "    print(f\"  Loss: {val_metrics['loss']:.4f} | Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"  Competition Score: {val_metrics['competition_score']:.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch+1}.pth')\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f'\\nCheckpoint saved: {checkpoint_path}')\n",
    "    \n",
    "    if val_metrics['competition_score'] > best_score:\n",
    "        best_score = val_metrics['competition_score']\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'Best model saved with Competition Score: {best_score:.4f}')\n",
    "\n",
    "print(f'\\nTraining completed!')\n",
    "print(f'Best validation Competition Score: {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da052b",
   "metadata": {
    "_cell_guid": "bc905498-75e1-4a34-ba41-b5ede6b63fee",
    "_uuid": "58ced5aa-0a54-4c13-8ce3-27e0ac6da602",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T13:40:41.569153Z",
     "iopub.status.busy": "2025-10-18T13:40:41.568774Z",
     "iopub.status.idle": "2025-10-18T13:40:42.381546Z",
     "shell.execute_reply": "2025-10-18T13:40:42.380787Z",
     "shell.execute_reply.started": "2025-10-18T13:40:41.569131Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_sd = torch.load(best_model_path)\n",
    "model.load_state_dict(best_sd)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e18f35",
   "metadata": {
    "_cell_guid": "a05e28d8-54b9-4217-a866-7721aa3300dc",
    "_uuid": "6648782f-58b9-4304-9678-2d057921b128",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b20006",
   "metadata": {
    "_cell_guid": "5aed540f-4388-407a-9e9c-9f76ca02872d",
    "_uuid": "0dd05536-ea07-4df9-8669-f1734e4fd9e6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:18:30.666603Z",
     "iopub.status.busy": "2025-10-18T14:18:30.666298Z",
     "iopub.status.idle": "2025-10-18T14:18:30.672982Z",
     "shell.execute_reply": "2025-10-18T14:18:30.672259Z",
     "shell.execute_reply.started": "2025-10-18T14:18:30.666582Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_predictions(all_predictions, aggregation='max', threshold=0.5, submission_name=None):\n",
    "    predictions = []\n",
    "    \n",
    "    for file_id, probs_list in all_predictions.items():\n",
    "        if aggregation == 'max':\n",
    "            final_prob = max(probs_list)\n",
    "        elif aggregation == 'mean':\n",
    "            final_prob = np.mean(probs_list)\n",
    "        elif aggregation == 'quantile_75':\n",
    "            final_prob = np.percentile(probs_list, 75)\n",
    "        elif aggregation == 'quantile_90':\n",
    "            final_prob = np.percentile(probs_list, 90)\n",
    "        elif aggregation == 'quantile_95':\n",
    "            final_prob = np.percentile(probs_list, 95)\n",
    "        else:\n",
    "            final_prob = max(probs_list)\n",
    "        \n",
    "        predictions.append({\n",
    "            'id': file_id,\n",
    "            'prob': final_prob\n",
    "        })\n",
    "\n",
    "    submission_df = pd.DataFrame(predictions)\n",
    "    submission_df['label'] = (submission_df['prob'] >= threshold).astype(int)\n",
    "    \n",
    "    if submission_name is not None:    \n",
    "        submission_final = submission_df[['id', 'label']]\n",
    "        submission_final.to_csv(submission_name, index=False)\n",
    "        print(f\"✓ Submission saved: {submission_name}\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb1950",
   "metadata": {
    "_cell_guid": "1e7e9786-2930-4c2f-9382-6b73cd34556b",
    "_uuid": "f8a532f5-e167-42fb-ba24-70f2edbe559b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:07:25.081973Z",
     "iopub.status.busy": "2025-10-18T14:07:25.081721Z",
     "iopub.status.idle": "2025-10-18T14:07:25.086977Z",
     "shell.execute_reply": "2025-10-18T14:07:25.086333Z",
     "shell.execute_reply.started": "2025-10-18T14:07:25.081955Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_score_from_predictions(submission_df, ground_truth, num_pos, num_neg):\n",
    "    \"\"\"\n",
    "    Вычисляет метрику соревнования по предсказаниям\n",
    "    \n",
    "    Args:\n",
    "        submission_df: DataFrame с колонками ['id', 'label']\n",
    "        ground_truth: dict {file_id: true_label}\n",
    "        num_pos: количество позитивных примеров\n",
    "        num_neg: количество негативных примеров\n",
    "    \n",
    "    Returns:\n",
    "        dict с метриками\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in submission_df.iterrows():\n",
    "        file_id = row['id']\n",
    "        if file_id in ground_truth:\n",
    "            preds.append(row['label'])\n",
    "            labels.append(ground_truth[file_id])\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    metrics = calculate_metrics(preds, labels, num_pos, num_neg)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26c4bd",
   "metadata": {
    "_cell_guid": "649bfe28-9946-4d75-add6-50ab41458dce",
    "_uuid": "cbd76b17-7e20-4228-a447-d4b3671e83ae",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test aggregations & threshold on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e43f4",
   "metadata": {
    "_cell_guid": "1203007f-fb99-436f-a5f9-9e653fde4673",
    "_uuid": "df24c51a-ec75-4890-a9ca-4c9ee7032b83",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:07:30.488907Z",
     "iopub.status.busy": "2025-10-18T14:07:30.488397Z",
     "iopub.status.idle": "2025-10-18T14:09:56.008465Z",
     "shell.execute_reply": "2025-10-18T14:09:56.007401Z",
     "shell.execute_reply.started": "2025-10-18T14:07:30.488887Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset_windowed = KWSTestDatasetWindowed(\n",
    "    [item[0] for item in val_items],\n",
    "    window_samples=test_window_samples,\n",
    "    hop_samples=test_hop_samples,\n",
    "    sr=sample_rate\n",
    ")\n",
    "\n",
    "val_loader_windowed = DataLoader(\n",
    "    val_dataset_windowed,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_test_windows,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf93186",
   "metadata": {
    "_cell_guid": "bc421801-7f9c-4dec-bffb-2d683f2d9cad",
    "_uuid": "4b49311e-e514-47b9-acf2-43f2953c9190",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:09:56.010134Z",
     "iopub.status.busy": "2025-10-18T14:09:56.009792Z",
     "iopub.status.idle": "2025-10-18T14:18:03.788264Z",
     "shell.execute_reply": "2025-10-18T14:18:03.787478Z",
     "shell.execute_reply.started": "2025-10-18T14:09:56.010116Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_all_predictions = defaultdict(list)\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    for input_values, file_ids, window_indices in tqdm(val_loader_windowed, desc='Validation inference'):\n",
    "        input_values = input_values.to(device)\n",
    "        \n",
    "        logits = model(input_values)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        probs_pos = probs[:, 1].cpu().numpy()\n",
    "        \n",
    "        for file_id, prob in zip(file_ids, probs_pos):\n",
    "            val_all_predictions[file_id].append(float(prob))\n",
    "\n",
    "val_ground_truth = {}\n",
    "for path, start_sec, end_sec in val_items:\n",
    "    file_id = Path(path).stem\n",
    "    label = 1 if start_sec is not None else 0\n",
    "    val_ground_truth[file_id] = label\n",
    "\n",
    "print(f\"✓ Validation predictions ready for {len(val_all_predictions)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42553eda",
   "metadata": {
    "_cell_guid": "232e1925-286c-411c-931f-a8e578382c7e",
    "_uuid": "3fd16c51-2059-4165-b15e-91613a6f681b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:23:58.657571Z",
     "iopub.status.busy": "2025-10-18T14:23:58.656860Z",
     "iopub.status.idle": "2025-10-18T14:25:09.977858Z",
     "shell.execute_reply": "2025-10-18T14:25:09.977240Z",
     "shell.execute_reply.started": "2025-10-18T14:23:58.657548Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregation_methods = ['max', 'mean', 'quantile_75', 'quantile_90', 'quantile_95']\n",
    "thresholds = np.arange(0.05, 0.96, 0.05)\n",
    "\n",
    "tuning_results = []\n",
    "\n",
    "for agg_method in aggregation_methods:\n",
    "    print(f\"\\nTesting aggregation: {agg_method}\")\n",
    "    \n",
    "    best_threshold = 0.5\n",
    "    best_score = 0\n",
    "    \n",
    "    for threshold in tqdm(thresholds, desc=f\"  {agg_method}\", leave=False):\n",
    "        submission_df = generate_predictions(\n",
    "            val_all_predictions,\n",
    "            aggregation=agg_method,\n",
    "            threshold=threshold,\n",
    "            submission_name=None\n",
    "        )\n",
    "        \n",
    "        metrics = calculate_score_from_predictions(\n",
    "            submission_df,\n",
    "            val_ground_truth,\n",
    "            val_num_pos,\n",
    "            val_num_neg\n",
    "        )\n",
    "        \n",
    "        tuning_results.append({\n",
    "            'aggregation': agg_method,\n",
    "            'threshold': round(threshold, 2),\n",
    "            'competition_score': metrics['competition_score'],\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'f1': metrics['f1']\n",
    "        })\n",
    "        \n",
    "        if metrics['competition_score'] > best_score:\n",
    "            best_score = metrics['competition_score']\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    print(f\"  Best: threshold={best_threshold:.2f}, score={best_score:.4f}\")\n",
    "\n",
    "tuning_df = pd.DataFrame(tuning_results)\n",
    "tuning_df.to_csv('tuning_results.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Tuning complete! Results saved to 'tuning_results.csv'\")\n",
    "tuning_df.head(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c2b0c",
   "metadata": {
    "_cell_guid": "c24f0c69-357d-4a6a-b5b1-7c8e86883564",
    "_uuid": "773e7b91-9c7d-4231-8830-bcf079728448",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference (sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74b82c",
   "metadata": {
    "_cell_guid": "2b2600fe-977d-4ee3-8a10-8840ad8a090d",
    "_uuid": "d0628572-4855-40f3-961f-5302267381c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T13:41:25.499190Z",
     "iopub.status.busy": "2025-10-18T13:41:25.498481Z",
     "iopub.status.idle": "2025-10-18T14:05:47.723369Z",
     "shell.execute_reply": "2025-10-18T14:05:47.722738Z",
     "shell.execute_reply.started": "2025-10-18T13:41:25.499164Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_all_predictions = defaultdict(list)\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    for input_values, file_ids, window_indices in tqdm(test_loader_windowed, desc='Predicting on test'):\n",
    "        input_values = input_values.to(device)\n",
    "        \n",
    "        logits = model(input_values)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        probs_pos = probs[:, 1].cpu().numpy()\n",
    "        \n",
    "        for file_id, prob in zip(file_ids, probs_pos):\n",
    "            test_all_predictions[file_id].append(float(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a44bd9",
   "metadata": {
    "_cell_guid": "0fe79d31-6cdf-48d5-98d1-5facd25a5967",
    "_uuid": "dfd6fbf1-e42e-4b87-bf5a-bf4669d22537",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T15:00:38.124463Z",
     "iopub.status.busy": "2025-10-18T15:00:38.123746Z",
     "iopub.status.idle": "2025-10-18T15:00:38.164815Z",
     "shell.execute_reply": "2025-10-18T15:00:38.164190Z",
     "shell.execute_reply.started": "2025-10-18T15:00:38.124433Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_filename = 'test_all_predictions.pkl'\n",
    "\n",
    "with open(pickle_filename, 'wb') as f:\n",
    "    pickle.dump(dict(test_all_predictions), f)\n",
    "\n",
    "pickle_size_mb = os.path.getsize(pickle_filename) / (1024 * 1024)\n",
    "print(f\"✓ Predictions saved: {pickle_filename} ({pickle_size_mb:.2f} MB)\")\n",
    "print(f\"✓ Total files: {len(test_all_predictions)}\")\n",
    "\n",
    "# with open('test_all_predictions.pkl', 'rb') as f:\n",
    "#     test_all_predictions = pickle.load(f)\n",
    "\n",
    "# print(f\"✓ Loaded predictions for {len(test_all_predictions)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebebdb5",
   "metadata": {
    "_cell_guid": "fb9bc146-e695-4676-8e4b-0523d15e1884",
    "_uuid": "8fbf55d3-bc4a-4bf6-9e4f-3c48aca590bf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:34:29.139516Z",
     "iopub.status.busy": "2025-10-18T14:34:29.138945Z",
     "iopub.status.idle": "2025-10-18T14:36:40.505937Z",
     "shell.execute_reply": "2025-10-18T14:36:40.505261Z",
     "shell.execute_reply.started": "2025-10-18T14:34:29.139493Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregation_methods = ['max', 'mean', 'quantile_75', 'quantile_90', 'quantile_95']\n",
    "thresholds = np.arange(0.05, 0.96, 0.05)\n",
    "\n",
    "submission_dir = 'submissions'\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "submission_log = []\n",
    "\n",
    "print(f\"Generating {len(aggregation_methods) * len(thresholds)} submissions...\")\n",
    "\n",
    "for agg_method in tqdm(aggregation_methods, desc=\"Aggregations\"):\n",
    "    for threshold in thresholds:\n",
    "        threshold_rounded = round(threshold, 2)\n",
    "        \n",
    "        filename = f\"{submission_dir}/submission_{agg_method}_th{threshold_rounded:.2f}.csv\"\n",
    "        \n",
    "        submission_df = generate_predictions(\n",
    "            test_all_predictions,\n",
    "            aggregation=agg_method,\n",
    "            threshold=threshold_rounded,\n",
    "            submission_name=filename\n",
    "        )\n",
    "        \n",
    "        pos_count = submission_df['label'].sum()\n",
    "        neg_count = len(submission_df) - pos_count\n",
    "        \n",
    "        submission_log.append({\n",
    "            'aggregation': agg_method,\n",
    "            'threshold': threshold_rounded,\n",
    "            'filename': Path(filename).name,\n",
    "            'positive_count': pos_count,\n",
    "            'negative_count': neg_count,\n",
    "            'positive_ratio': pos_count / len(submission_df)\n",
    "        })\n",
    "\n",
    "submission_log_df = pd.DataFrame(submission_log)\n",
    "submission_log_df.to_csv(f'{submission_dir}/submission_log.csv', index=False)\n",
    "\n",
    "print(f\"✓ Generated {len(submission_log)} submissions in '{submission_dir}/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451471ec",
   "metadata": {
    "_cell_guid": "f902bd20-920e-45f3-a0fd-ff12e9209497",
    "_uuid": "ffcea88e-ad78-453c-8439-816e41259e54",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:38:41.147523Z",
     "iopub.status.busy": "2025-10-18T14:38:41.147198Z",
     "iopub.status.idle": "2025-10-18T14:38:41.169481Z",
     "shell.execute_reply": "2025-10-18T14:38:41.168918Z",
     "shell.execute_reply.started": "2025-10-18T14:38:41.147501Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_csv('submissions/submission_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21cb59",
   "metadata": {
    "_cell_guid": "f5596a7b-b613-45b0-aaf9-465c6305fe8b",
    "_uuid": "4512f648-d7bc-4c09-8407-72e113d12b9a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:40:21.705319Z",
     "iopub.status.busy": "2025-10-18T14:40:21.704826Z",
     "iopub.status.idle": "2025-10-18T14:40:36.290276Z",
     "shell.execute_reply": "2025-10-18T14:40:36.289577Z",
     "shell.execute_reply.started": "2025-10-18T14:40:21.705297Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Generating balanced (50/50) submissions...\")\n",
    "\n",
    "balanced_submissions = []\n",
    "total_samples = len(test_all_predictions)\n",
    "target_positive = total_samples // 2\n",
    "\n",
    "for agg_method in aggregation_methods:\n",
    "    all_probs = []\n",
    "    for file_id, probs_list in test_all_predictions.items():\n",
    "        if agg_method == 'max':\n",
    "            final_prob = max(probs_list)\n",
    "        elif agg_method == 'mean':\n",
    "            final_prob = np.mean(probs_list)\n",
    "        elif agg_method == 'quantile_75':\n",
    "            final_prob = np.percentile(probs_list, 75)\n",
    "        elif agg_method == 'quantile_90':\n",
    "            final_prob = np.percentile(probs_list, 90)\n",
    "        elif agg_method == 'quantile_95':\n",
    "            final_prob = np.percentile(probs_list, 95)\n",
    "        else:\n",
    "            final_prob = max(probs_list)\n",
    "        \n",
    "        all_probs.append(final_prob)\n",
    "    \n",
    "    all_probs_sorted = sorted(all_probs, reverse=True)\n",
    "    \n",
    "    balanced_threshold = all_probs_sorted[target_positive]\n",
    "    balanced_threshold = round(balanced_threshold, 3)\n",
    "    \n",
    "    filename = f\"{submission_dir}/submission_{agg_method}_balanced50.csv\"\n",
    "    \n",
    "    submission_df = generate_predictions(\n",
    "        test_all_predictions,\n",
    "        aggregation=agg_method,\n",
    "        threshold=balanced_threshold,\n",
    "        submission_name=filename\n",
    "    )\n",
    "    \n",
    "    pos_count = submission_df['label'].sum()\n",
    "    neg_count = len(submission_df) - pos_count\n",
    "    \n",
    "    balanced_submissions.append({\n",
    "        'aggregation': agg_method,\n",
    "        'threshold': balanced_threshold,\n",
    "        'filename': Path(filename).name,\n",
    "        'positive_count': pos_count,\n",
    "        'negative_count': neg_count,\n",
    "        'positive_ratio': pos_count / len(submission_df)\n",
    "    })\n",
    "    \n",
    "    print(f\"  {agg_method}: th={balanced_threshold:.3f}, pos={pos_count}, neg={neg_count}\")\n",
    "\n",
    "balanced_df = pd.DataFrame(balanced_submissions)\n",
    "balanced_df.to_csv(f'{submission_dir}/balanced_submissions.csv', index=False)\n",
    "\n",
    "print(f\"\\n✓ Generated {len(balanced_submissions)} balanced submissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ddfd8",
   "metadata": {
    "_cell_guid": "95a744c9-e448-4edf-985e-21a4b29aec41",
    "_uuid": "1bb4c2aa-1e30-4953-a0b8-89222f07b600",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-18T14:43:56.878790Z",
     "iopub.status.busy": "2025-10-18T14:43:56.878506Z",
     "iopub.status.idle": "2025-10-18T14:44:07.004422Z",
     "shell.execute_reply": "2025-10-18T14:44:07.003697Z",
     "shell.execute_reply.started": "2025-10-18T14:43:56.878773Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive('submissions', 'zip', submission_dir)\n",
    "\n",
    "zip_size_mb = os.path.getsize('submissions.zip') / (1024 * 1024)\n",
    "print(f\"✓ Archive: submissions.zip ({zip_size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1f0d2",
   "metadata": {
    "_cell_guid": "e4f6962e-38cc-4dfe-a202-7a06a2d40a01",
    "_uuid": "c2247541-1d95-4f40-9cd5-2875c32fa00f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8513195,
     "sourceId": 13416429,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 784.914388,
   "end_time": "2025-10-18T16:21:59.726887",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-18T16:08:54.812499",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
